{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648e5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbf6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - patience (int): The number of epochs with no improvement after which training will be stopped.\n",
    "        - delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.patience_counter = 0\n",
    "\n",
    "    def should_stop(self, current_loss):\n",
    "        \"\"\"Check whether to stop training.\"\"\"\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = current_loss\n",
    "            return False\n",
    "        elif current_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = current_loss\n",
    "            self.patience_counter = 0\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "        \n",
    "        if self.patience_counter >= self.patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Check if GPU is available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load the pretrained YOLOv8 medium classification model\n",
    "    model = YOLO('yolov8m-cls.pt').to(device)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, delta=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(100):  # Train for 100 epochs\n",
    "        print(f\"Epoch {epoch+1}/100\")\n",
    "\n",
    "        # Train for one epoch\n",
    "        results = model.train(\n",
    "            data='datasets\\diff-types',  # path to your dataset (root folder)\n",
    "            epochs=1,                   # train for one epoch at a time\n",
    "            batch=8,                    # batch size\n",
    "            imgsz=224,                  # image size\n",
    "            device=0,                   # use GPU (0 means first GPU)\n",
    "            workers=4,                  # number of worker threads\n",
    "            optimizer='Adam',           # optimizer\n",
    "            lr0=0.001,                  # initial learning rate\n",
    "            seed=42                     # random seed\n",
    "        )\n",
    "\n",
    "        # Get the current validation loss (this will depend on your model)\n",
    "        current_loss = results.metrics['val/loss']  # assuming validation loss is available\n",
    "        \n",
    "        # Check if early stopping should be triggered\n",
    "        if early_stopping.should_stop(current_loss):\n",
    "            print(\"Stopping early due to no improvement.\")\n",
    "            break\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save('e-waste-classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74d099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/100\n",
      "Ultralytics 8.3.109  Python-3.11.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=datasets\\diff-types, epochs=1, time=None, patience=100, batch=8, imgsz=224, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m R:\\Projects\\E-Waste Management\\Codes\\datasets\\diff-types\\train... found 2400 images in 10 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m R:\\Projects\\E-Waste Management\\Codes\\datasets\\diff-types\\val... found 300 images in 10 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m R:\\Projects\\E-Waste Management\\Codes\\datasets\\diff-types\\test... found 300 images in 10 classes  \n",
      "Overriding model.yaml nc=1000 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    998410  ultralytics.nn.modules.head.Classify         [768, 10]                     \n",
      "YOLOv8m-cls summary: 80 layers, 15,785,146 parameters, 15,785,146 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 14.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning R:\\Projects\\E-Waste Management\\Codes\\datasets\\diff-types\\train... 2400 images, 0 corrupt: 100%|██████████| 2400/2400 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning R:\\Projects\\E-Waste Management\\Codes\\datasets\\diff-types\\val... 300 images, 0 corrupt: 100%|██████████| 300/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1     0.697G       1.16          8        224: 100%|██████████| 300/300 [00:22<00:00, 13.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:00<00:00, 19.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.92      0.997\n",
      "\n",
      "1 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs\\classify\\train\\weights\\last.pt, 31.7MB\n",
      "Optimizer stripped from runs\\classify\\train\\weights\\best.pt, 31.7MB\n",
      "\n",
      "Validating runs\\classify\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.109  Python-3.11.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLOv8m-cls summary (fused): 42 layers, 15,775,466 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m R:\\Projects\\E-Waste Management\\Codes\\datasets\\diff-types\\train... found 2400 images in 10 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m R:\\Projects\\E-Waste Management\\Codes\\datasets\\diff-types\\val... found 300 images in 10 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m R:\\Projects\\E-Waste Management\\Codes\\datasets\\diff-types\\test... found 300 images in 10 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 19/19 [00:00<00:00, 28.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.92      0.997\n",
      "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ClassifyMetrics' object has no attribute 'metrics'. See valid attributes below.\n\n    Class for computing classification metrics including top-1 and top-5 accuracy.\n\n    Attributes:\n        top1 (float): The top-1 accuracy.\n        top5 (float): The top-5 accuracy.\n        speed (dict): A dictionary containing the time taken for each step in the pipeline.\n        task (str): The task type, set to 'classify'.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 59\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     47\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdiff-types\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# path to your dataset (root folder)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,                   \u001b[38;5;66;03m# train for one epoch at a time\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m                     \u001b[38;5;66;03m# random seed\u001b[39;00m\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Get the current validation loss (this will depend on your model)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/loss\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# assuming validation loss is available\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Check if early stopping should be triggered\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m early_stopping\u001b[38;5;241m.\u001b[39mshould_stop(current_loss):\n",
      "File \u001b[1;32mr:\\Projects\\E-Waste Management\\Codes\\e-waste-env\\Lib\\site-packages\\ultralytics\\utils\\__init__.py:241\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ClassifyMetrics' object has no attribute 'metrics'. See valid attributes below.\n\n    Class for computing classification metrics including top-1 and top-5 accuracy.\n\n    Attributes:\n        top1 (float): The top-1 accuracy.\n        top5 (float): The top-5 accuracy.\n        speed (dict): A dictionary containing the time taken for each step in the pipeline.\n        task (str): The task type, set to 'classify'.\n    "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52e92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e-waste-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
